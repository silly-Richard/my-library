---
{"dg-publish":true,"permalink":"/3.词条/回归分析/","created":"2024-04-28T21:05:16.624+08:00"}
---


回归分析（regression analysis）是确定两个或两个以上变量之间相互依赖的定量关系的分析方法。按照涉及变量的多少可以分为一元回归分析和多元回归分析；按照自变量与因变量之间关系类型可分为线性回归分析和非线性回归分析。

# 回归分析的分析流程

1. 确定自变量x和因变量y。因变量是实际研究中我们关心的对象指标，而影响因变量变化的因素为自变量。
2. 确定y与x之间的定量关系表达式，建立回归模型。
3. 对回归模型的可信度进行检验。
4. 判断自变量x与因变量y之间有无关系。
5. 利用所建立的模型进行预测和控制。

## 建立回归模型

以一元线性回归模型为例，将表格中x和y值以散点的形式绘制在图表中，绘制一条直线使得该直线尽可能通过图表中绝大多数的散点，或使未通过的点能够随机均匀紧密分布在直线的两侧。这条直线被称为最佳拟合曲线。该曲线的函数表达式即为回归模型函数。

其中，a为回归系数（regression coefficient）,b为截距（intercept）。

## 模型可信度检验

### F-test F检验